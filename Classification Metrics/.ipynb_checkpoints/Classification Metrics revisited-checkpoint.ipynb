{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"advanced-classification-metrics\"></a>\n",
    "## Classification Metrics\n",
    "\n",
    "---\n",
    "\n",
    "When we evaluate the performance of a logistic regression (or any classifier model), the standard metric to use is accuracy: How many class labels did we guess correctly? However, accuracy is only one of several metrics we could use when evaluating a classification model.\n",
    "\n",
    "$$Accuracy = \\frac{total~predicted~correct}{total~predicted}$$\n",
    "\n",
    "Accuracy alone doesn’t always give us a full picture.\n",
    "\n",
    "If we know a model is 75% accurate, it doesn’t provide any insight into why the 25% was wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a binary classification problem where we have 165 observations/rows of people who are either smokers or nonsmokers.\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60 in class 0, nonsmokers, and 105 observations in class 1, smokers\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 55 predictions of class, predicted as nonsmokers, and 110 of class 1, predicted to be smokers.\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **True positives (TP):** These are cases in which we predicted yes (smokers), and they actually are smokers.\n",
    "- **True negatives (TN):** We predicted no, and they are nonsmokers.\n",
    "- **False positives (FP):** We predicted yes, but they were not actually smokers. (This is also known as a \"Type I error.\")\n",
    "- **False negatives (FN):** We predicted no, but they are smokers. (This is also known as a \"Type II error.\")\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorize these as TP, TN, FP, or FN:**\n",
    "\n",
    "Try not to look at the answers above.\n",
    "    \n",
    "- We predict nonsmoker, but the person is a smoker.\n",
    "- We predict nonsmoker, and the person is a nonsmoker.\n",
    "- We predict smoker and the person is a smoker.\n",
    "- We predict smoker and the person is a nonsmoker.\n",
    "\n",
    "<!--ANSWER\n",
    "- FN\n",
    "- TN\n",
    "- TP\n",
    "- FP\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"accuracy-true-positive-rate-and-false-negative-rate\"></a>\n",
    "### Accuracy, True Positive Rate, and False Negative Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** Overall, how often is the classifier correct?\n",
    "\n",
    "<span>\n",
    "    (<span style=\"color: green\">TP</span>+<span style=\"color: red\">TN</span>)/<span style=\"color: blue\">total</span> = (<span style=\"color: green\">100</span>+<span style=\"color: red\">50</span>)/<span style=\"color: blue\">165</span> = 0.91\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom; color: blue\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center; background-color: red\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center; background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True positive rate (TPR)** asks, “Out of all of the target class labels, how many were accurately predicted to belong to that class?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it correctly identify patients with cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: green\">TP</span>/<span style=\"color: blue\">actual yes</span> = <span style=\"color: green\">100</span>/<span style=\"color: blue\">105</span> = 0.95\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center;background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center;color: blue\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**False positive rate (FPR)** asks, “Out of all items not belonging to a class label, how many were predicted as belonging to that target class label?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it trigger a “false alarm” by incorrectly saying a patient has cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: orange\">FP</span>/<span style=\"color: blue\">actual no</span> = <span style=\"color: orange\">10</span>/<span style=\"color: blue\">60</span> = 0.17\n",
    "</span>\n",
    "\n",
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center;background-color: orange\">FP = 10</td>\n",
    "    <td style=\"text-align: center;color:blue\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you see that we might weigh TPR AND FPR differently depending on the situation?**\n",
    "\n",
    "- Give an example when we care about TPR, but not FPR.\n",
    "- Give an example when we care about FPR, but not TPR.\n",
    "\n",
    "<!--\n",
    "ANSWER:\n",
    "- During an initial medical diagnosis, we want to be sensitive. We want initial screens to come up with a lot of true positives, even if we get a lot of false positives.\n",
    "- If we are doing spam detection, we want to be precise. Anything that we remove from an inbox must be spam, which may mean accepting fewer true positives.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Trade-Offs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true positive and false positive rates gives us a much clearer picture of where predictions begin to fall apart.\n",
    "\n",
    "This allows us to adjust our models accordingly.\n",
    "\n",
    "**Below we will load in some data on admissions to college.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:42:40.670061Z",
     "start_time": "2021-07-10T10:42:40.666308Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:42:41.144291Z",
     "start_time": "2021-07-10T10:42:41.136778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in your admissions data...\n",
    "admissions = pd.read_csv(# Complete...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing rows...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:42:41.919530Z",
     "start_time": "2021-07-10T10:42:41.914126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dummy variables for prestige. Code provided...\n",
    "admissions = admissions.join(pd.get_dummies(admissions['prestige'], prefix='prestige'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T07:20:25.155312Z",
     "start_time": "2021-07-13T07:20:25.152810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check your work...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can predict the `admit` class from `gre` and use a train-test split to evaluate the performance of our model on a held-out test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:42:47.466583Z",
     "start_time": "2021-07-10T10:42:47.463105Z"
    }
   },
   "outputs": [],
   "source": [
    "X = # complete\n",
    "y = # complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:44:30.310711Z",
     "start_time": "2021-07-10T10:44:30.303049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((297, 1), (100, 1), (297,), (100,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(# Complete....)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:44:30.595550Z",
     "start_time": "2021-07-10T10:44:30.581561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create or instantiate your model object\n",
    "logreg = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall that our \"baseline\" accuracy is the proportion of the majority class label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:44:31.034072Z",
     "start_time": "2021-07-10T10:44:31.029612Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6835016835016835"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1. - y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:48:36.399834Z",
     "start_time": "2021-07-10T10:48:36.394752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(# complete....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a confusion matrix of predictions on our test set using `metrics.confusion_matrix`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:44:31.691327Z",
     "start_time": "2021-07-10T10:44:31.686638Z"
    }
   },
   "outputs": [],
   "source": [
    "y_preds = # complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:44:32.092478Z",
     "start_time": "2021-07-10T10:44:32.087008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  1],\n",
       "       [31,  1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(# complete...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom; color: blue\">n = ?</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center; \">TN = ?</td>\n",
    "    <td style=\"text-align: center\">FP = ?</td>\n",
    "    <td style=\"text-align: center\">?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = ?</td>\n",
    "    <td style=\"text-align: center; \">TP = ?</td>\n",
    "    <td style=\"text-align: center\">?</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">?</td>\n",
    "    <td style=\"text-align: center\">?</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:42:51.078270Z",
     "start_time": "2021-07-10T10:42:51.073264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get probability predictions.\n",
    "logreg_pred_proba = # Complete..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:42:51.678987Z",
     "start_time": "2021-07-10T10:42:51.672479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  1],\n",
       "       [31,  1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(# Complete...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the following:**\n",
    "\n",
    "- What is our accuracy?\n",
    "- True positive rate?\n",
    "- False positive rate?\n",
    "\n",
    "<!--\n",
    "ANSWER: This will depend on the data\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-10T10:40:04.720318Z",
     "start_time": "2021-07-10T10:40:04.717543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"good\" classifier would have a true positive rate approaching 1 and a false positive rate approaching 0.\n",
    "\n",
    "In our smoking problem, this model would accurately predict the majority of the smokers as smokers and not predict too many of the nonsmokers as smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T07:23:05.816161Z",
     "start_time": "2021-07-13T07:23:05.813397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Anything else you'd like to do?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading True Positives and True Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, and with respect to the underlying assumptions of logistic regression, we predict a positive class when the probability of the class is greater than .5 and predict a negative class otherwise.\n",
    "\n",
    "What if we decide to use .3 as a threshold for picking the positive class? Is that even allowed?\n",
    "\n",
    "This turns out to be a useful strategy. By setting a lower probability threshold we will predict more positive classes. Which means we will predict more true positives, but fewer true negatives.\n",
    "\n",
    "Making this trade-off is important in applications that have imbalanced penalties for misclassification.\n",
    "\n",
    "The most popular example is medical diagnostics, where we want as many true positives as feasible. For example, if we are diagnosing cancer we prefer to have false positives, predict a cancer when there is no cancer, that can be later corrected with a more specific test.\n",
    "\n",
    "We do this in machine learning by setting a low threshold for predicting positives which increases the number of true positives and false positives, but allows us to balance the the costs of being correct and incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can vary the classification threshold for our model to get different predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-13T07:22:17.778229Z",
     "start_time": "2021-07-13T07:22:17.775539Z"
    }
   },
   "outputs": [],
   "source": [
    "# We'll do this together in class and discuss...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Accuracy Paradox\n",
    "\n",
    "Accuracy is a very intuitive metric — it's a lot like an exam score where you get total correct/total attempted. However, accuracy is often a poor metric in application. There are many reasons for this:\n",
    "- Imbalanced problems problems with 95% positives in the baseline will have 95% accuracy even with no predictive power.\n",
    "  - This is the paradox; pursuing accuracy often means predicting the most common class rather than doing the most useful work.\n",
    "- Applications often have uneven penalties and rewards for true positives and false positives.\n",
    "- Ranking predictions in the correct order be more important than getting them correct.\n",
    "- In many case we need to know the exact probability of a positives and negatives.\n",
    "  - To calculate an expected return.\n",
    "  - To triage observations that are borderline positive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
